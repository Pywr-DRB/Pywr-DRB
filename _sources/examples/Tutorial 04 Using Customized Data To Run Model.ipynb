{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 04 – Using Customized Data to Run Pywr-DRB\n",
    "\n",
    "In addition to built-in inflow and diversion datasets, Pywr-DRB allows users to supply their own customized input data. This tutorial explains how to integrate external inflow or diversion files using the model’s path configuration system.\n",
    "\n",
    "You will learn:\n",
    "\n",
    "- How dataset paths are managed in Pywr-DRB using the `PathNavigator`  \n",
    "- How to register and use custom folders for flow and diversion data  \n",
    "- What files must be present for a valid custom input folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 – Understanding the Path Structure\n",
    "\n",
    "Pywr-DRB uses a centralized [`PathNavigator`](https://github.com/philip928lin/PathNavigator) object to manage file paths for input datasets, including flows, diversions, observations, and operational constants.\n",
    "\n",
    "The `PathNavigator` stores all dataset directories in a structured configuration that Pywr-DRB references when building or running a model.\n",
    "\n",
    "You can inspect the current path configuration using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flows/nhmv10': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nhmv10',\n",
      " 'flows/nhmv10_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nhmv10_withObsScaled',\n",
      " 'flows/nwmv21': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nwmv21',\n",
      " 'flows/nwmv21_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nwmv21_withObsScaled',\n",
      " 'flows/pub_nhmv10_BC_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\pub_nhmv10_BC_withObsScaled',\n",
      " 'flows/wrf1960s_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrf1960s_calib_nlcd2016',\n",
      " 'flows/wrf2050s_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrf2050s_calib_nlcd2016',\n",
      " 'flows/wrfaorc_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrfaorc_calib_nlcd2016',\n",
      " 'flows/wrfaorc_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrfaorc_withObsScaled'}\n"
     ]
    }
   ],
   "source": [
    "import pywrdrb\n",
    "from pprint import pprint\n",
    "\n",
    "pn_config = pywrdrb.get_pn_config()\n",
    "pprint(pn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The printed dictionary shows the current registered dataset paths. Each entry uses a key like `flows/nhmv10` or `diversions/nwmv21` to identify the type and name of the dataset, and maps it to a corresponding local directory.\n",
    "\n",
    "From this configuration, you can see that Pywr-DRB includes several built-in inflow and diversion datasets:\n",
    "\n",
    "- Inflow types: `nhmv10`, `nhmv10_withObsScaled`, `nwmv21`, `nwmv21_withObsScaled`, `wrf1960s_calib_nlcd2016`, `wrf2050s_calib_nlcd2016`, and `wrfaorc_calib_nlcd2016`  \n",
    "- Diversion types: matching diversion data folders exist for each of the inflow types listed above\n",
    "\n",
    "Each dataset folder is stored under a prefix (`flows/` or `diversions/`) to distinguish the type of input data. These paths are referenced during model building when you specify `inflow_type` and `diversion_type`.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 – Registering a Custom Dataset\n",
    "\n",
    "If you want to use your own inflow data stored in a folder like `C:/my_data`, you can add it to the path configuration and register it with a custom name (e.g., `\"my_data\"`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn_config = pywrdrb.get_pn_config()\n",
    "pn_config[\"flows/my_data\"] = \"C:/my_data\"\n",
    "pywrdrb.load_pn_config(pn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once registered, you can build the model using your custom data by passing \"my_data\" as the inflow_type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb = pywrdrb.ModelBuilder(\n",
    "    inflow_type=\"my_data\",\n",
    "    diversion_type=\"nhmv10\",  # or another supported diversion dataset\n",
    "    start_date=\"1983-10-01\",\n",
    "    end_date=\"1985-12-31\"\n",
    ")\n",
    "mb.make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset is not properly registered or does not include the required files, ModelBuilder will raise an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 – Required Files for Custom Inflow Data\n",
    "\n",
    "Your custom inflow folder must include the following **three files**:\n",
    "\n",
    "- `catchment_inflow_mgd.csv`  \n",
    "- `gage_flow_mgd.csv`  \n",
    "- `predicted_inflows_mgd.csv`\n",
    "\n",
    "Each file should:\n",
    "\n",
    "- Be a CSV file with a `datetime` column\n",
    "- Include columns for relevant nodes or locations (e.g., reservoirs or catchments)\n",
    "- Use consistent formatting and overlapping date ranges across all files\n",
    "\n",
    "To preview the expected format, you can inspect the structure of the built-in `nhmv10` inflow folder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required files: ['catchment_inflow_mgd.csv', 'gage_flow_mgd.csv', 'predicted_inflows_mgd.csv']\n",
      "\n",
      "Preview: catchment_inflow_mgd.csv\n",
      "     datetime  cannonsville    pepacton   neversink  wallenpaupack\n",
      "0  1980-10-01    130.379373   89.325193   60.718368      33.438627\n",
      "1  1980-10-02    320.876434  234.425929   58.710650     155.951484\n",
      "2  1980-10-03    384.188487  261.300230   71.301161     196.969214\n",
      "3  1980-10-04    345.220715  265.843778  115.661384     229.965044\n",
      "4  1980-10-05    322.869093  257.040294   71.100223     208.087549\n",
      "\n",
      "Preview: gage_flow_mgd.csv\n",
      "     datetime  cannonsville    pepacton   neversink  wallenpaupack\n",
      "0  1980-10-01    130.379373   89.325193   60.718368      33.438627\n",
      "1  1980-10-02    320.876434  234.425929   58.710650     155.951484\n",
      "2  1980-10-03    384.188487  261.300230   71.301161     196.969214\n",
      "3  1980-10-04    345.220715  265.843778  115.661384     229.965044\n",
      "4  1980-10-05    322.869093  257.040294   71.100223     208.087549\n",
      "\n",
      "Preview: predicted_inflows_mgd.csv\n",
      "     datetime  delMontague_lag1_regression_disagg  \\\n",
      "0  1983-10-01                          229.021075   \n",
      "1  1983-10-02                          437.812448   \n",
      "2  1983-10-03                         1091.191061   \n",
      "3  1983-10-04                         1367.417389   \n",
      "4  1983-10-05                         1046.802593   \n",
      "\n",
      "   delMontague_lag2_regression_disagg  delTrenton_lag1_regression_disagg  \\\n",
      "0                          407.304641                          34.783055   \n",
      "1                          846.733954                         330.528839   \n",
      "2                         1608.726450                        1597.578624   \n",
      "3                         1845.161086                        2856.923949   \n",
      "4                         1512.261956                        1945.907752   \n",
      "\n",
      "   delTrenton_lag2_regression_disagg  \n",
      "0                         312.558400  \n",
      "1                         654.031017  \n",
      "2                        2743.665878  \n",
      "3                        4238.030173  \n",
      "4                        2924.458661  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pn = pywrdrb.get_pn_object()\n",
    "files = pn.flows.nhmv10.list()\n",
    "\n",
    "print(\"Required files:\", files)\n",
    "for file in files:\n",
    "    df = pd.read_csv(pn.flows.nhmv10.get(file))\n",
    "    print(f\"\\nPreview: {file}\")\n",
    "    print(df.iloc[:5, :5])  # first 5 rows and 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your files use the same column names and structure so they can be correctly interpreted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 – Required Files for Custom Diversion Data\n",
    "\n",
    "If you are providing your own diversion data, your custom diversion folder must include the following **three files**:\n",
    "\n",
    "- `diversion_nj_extrapolated_mgd.csv`  \n",
    "- `diversion_nyc_extrapolated_mgd.csv`  \n",
    "- `predicted_diversions_mgd.csv`\n",
    "\n",
    "Each file should:\n",
    "\n",
    "- Be a CSV file with a `datetime` column\n",
    "- Include relevant diversion points as columns (e.g., `D_R_Canal`, `cannonsville`, `aggregate`)\n",
    "- Match the date range of your inflow data\n",
    "\n",
    "To preview the expected format, you can inspect the default diversion dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current path configuration\n",
    "pn_config = pywrdrb.get_pn_config()\n",
    "\n",
    "# Register your custom inflow directory\n",
    "pn_config[\"flows/my_data\"] = pn_config[\"flows/nhmv10\"]  # Replace with your own path\n",
    "\n",
    "# Reload the configuration into PywrDRB\n",
    "pywrdrb.load_pn_config(pn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use my_data as the inflow_type when building the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully using custom inflow type.\n"
     ]
    }
   ],
   "source": [
    "mb = pywrdrb.ModelBuilder(\n",
    "    inflow_type='my_data',\n",
    "    diversion_type='nhmv10',  # You can customize this as well\n",
    "    start_date=\"1983-10-01\",\n",
    "    end_date=\"1985-12-31\"\n",
    ")\n",
    "\n",
    "# Create model JSON\n",
    "mb.make_model()\n",
    "print(\"Model created successfully using custom inflow type.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets you need to have in your customize \"my_folder\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For flow type folder, you need to have the following files: \n",
      "\n",
      "File needed: ['catchment_inflow_mgd.csv', 'gage_flow_mgd.csv', 'predicted_inflows_mgd.csv']\n",
      "\n",
      "File: catchment_inflow_mgd.csv\n",
      "     datetime  cannonsville    pepacton   neversink  wallenpaupack\n",
      "0  1980-10-01    130.379373   89.325193   60.718368      33.438627\n",
      "1  1980-10-02    320.876434  234.425929   58.710650     155.951484\n",
      "2  1980-10-03    384.188487  261.300230   71.301161     196.969214\n",
      "3  1980-10-04    345.220715  265.843778  115.661384     229.965044\n",
      "4  1980-10-05    322.869093  257.040294   71.100223     208.087549\n",
      "\n",
      "\n",
      "File: gage_flow_mgd.csv\n",
      "     datetime  cannonsville    pepacton   neversink  wallenpaupack\n",
      "0  1980-10-01    130.379373   89.325193   60.718368      33.438627\n",
      "1  1980-10-02    320.876434  234.425929   58.710650     155.951484\n",
      "2  1980-10-03    384.188487  261.300230   71.301161     196.969214\n",
      "3  1980-10-04    345.220715  265.843778  115.661384     229.965044\n",
      "4  1980-10-05    322.869093  257.040294   71.100223     208.087549\n",
      "\n",
      "\n",
      "File: predicted_inflows_mgd.csv\n",
      "     datetime  delMontague_lag1_regression_disagg  \\\n",
      "0  1983-10-01                          229.021075   \n",
      "1  1983-10-02                          437.812448   \n",
      "2  1983-10-03                         1091.191061   \n",
      "3  1983-10-04                         1367.417389   \n",
      "4  1983-10-05                         1046.802593   \n",
      "\n",
      "   delMontague_lag2_regression_disagg  delTrenton_lag1_regression_disagg  \\\n",
      "0                          407.304641                          34.783055   \n",
      "1                          846.733954                         330.528839   \n",
      "2                         1608.726450                        1597.578624   \n",
      "3                         1845.161086                        2856.923949   \n",
      "4                         1512.261956                        1945.907752   \n",
      "\n",
      "   delTrenton_lag2_regression_disagg  \n",
      "0                         312.558400  \n",
      "1                         654.031017  \n",
      "2                        2743.665878  \n",
      "3                        4238.030173  \n",
      "4                        2924.458661  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"For flow type folder, you need to have the following files: \\n\")\n",
    "pn = pywrdrb.get_pn_object()\n",
    "files = pn.flows.nhmv10.list()\n",
    "print(f\"File needed: {files}\\n\")  \n",
    "for file in files:\n",
    "    df = pd.read_csv(pn.flows.nhmv10.get(file))\n",
    "    print(f\"File: {file}\")\n",
    "    print(df.iloc[:5, :5]) # print first 5 rows and 5 columns\n",
    "    print(\"\\n\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More About the Global PathNavigator Object Used in PywrDRB\n",
    "\n",
    "We can get the global `PathNavigator` object used in PywrDRB by running: `pn = pywrdrb.get_pn_object()`\n",
    "\n",
    "This `pn` object contains all the directory and path information, allowing you to locate specific files used in PywrDRB within the file explorer.\n",
    "\n",
    "More `pn` operations can be found [here](https://github.com/philip928lin/PathNavigator). However, users should ONLY use pn to explore file and folder locations. It is not designed for modifications unless you fully understand what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root directory of the pywrdrb: C:\\Users\\CL\\Documents\\GitHub\\Pywr-DRB\\src\\pywrdrb\\data\n"
     ]
    }
   ],
   "source": [
    "pn = pywrdrb.get_pn_object()\n",
    "print(f\"The root directory of the pywrdrb: {pn.get()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also scan and print the folder structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.scan(max_depth=2)  # scan the directory structure up to 2 levels deep\n",
    "pn.tree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
