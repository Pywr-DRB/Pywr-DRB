{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Customized Data To Run PywrDRB\n",
    "\n",
    "PywrDRB provides multiple `inflow_type` and `diversion_type` options for users to select directly during the model-building process. However, sometimes users may want to use their own customized data to run the model.\n",
    "\n",
    "In this tutorial, we will walk you through:  \n",
    "1) The path structure adopted in PywrDRB.  \n",
    "2) How to use your own flow and diversion data to run the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Structure in PywrDRB\n",
    "\n",
    "In PywrDRB, we use a global instance of the [PathNavigator](https://github.com/philip928lin/PathNavigator) object to manage the paths associated with different datasets used in PywrDRB.\n",
    "\n",
    "To get the customizable path configuration, you can do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flows/nhmv10': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nhmv10',\n",
      " 'flows/nhmv10_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nhmv10_withObsScaled',\n",
      " 'flows/nwmv21': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nwmv21',\n",
      " 'flows/nwmv21_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\nwmv21_withObsScaled',\n",
      " 'flows/pub_nhmv10_BC_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\pub_nhmv10_BC_withObsScaled',\n",
      " 'flows/wrf1960s_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrf1960s_calib_nlcd2016',\n",
      " 'flows/wrf2050s_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrf2050s_calib_nlcd2016',\n",
      " 'flows/wrfaorc_calib_nlcd2016': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrfaorc_calib_nlcd2016',\n",
      " 'flows/wrfaorc_withObsScaled': 'C:\\\\Users\\\\CL\\\\Documents\\\\GitHub\\\\Pywr-DRB\\\\src\\\\pywrdrb\\\\data\\\\flows\\\\wrfaorc_withObsScaled'}\n"
     ]
    }
   ],
   "source": [
    "import pywrdrb\n",
    "from pprint import pprint\n",
    "\n",
    "pn_config = pywrdrb.get_pn_config()\n",
    "pprint(pn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you can see that we provide five inflow types: `nhmv10`, `nhmv10_withObsScaled`, `nwmv21`, `nwmv21_withObsScaled`, `wrf1960s_calib_nlcd2016`, `wrf2050s_calib_nlcd2016`, and `wrfaorc_calib_nlcd2016`, along with the corresponding five diversion types: `nhmv10`, `nhmv10_withObsScaled`, `nwmv21`, `nwmv21_withObsScaled`, `wrf1960s_calib_nlcd2016`, `wrf2050s_calib_nlcd2016`, and `wrfaorc_calib_nlcd2016`. \n",
    "\n",
    "The directories of the corresponding folders are stored in a dictionary, where the keys have the prefix `flows/` and `diversions/` to distinguish between flow data and diversion data.\n",
    "\n",
    "So, if you want to use your own data to run the simulation, you will need to add your folder directory to `pn_config` and load it into `pywrdrb` before building and running the model. \n",
    "\n",
    "Let me show you how. Assuming you want to use your own flow datasets (we will discuss the required datasets soon) stored in an external folder `C:/my_data`, you need to add `{\"flows/my_data\": \"C:/my_data\"}` to `pn_config`. Then, you can use `my_data` as the flow type when using the `modelbuilder`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before adding the custom config if we try to use the custom inflow type, it will raise an error\n",
    "\n",
    "r\"\"\"\n",
    "mb = pywrdrb.ModelBuilder(\n",
    "    inflow_type='my_data', \n",
    "    diversion_type='nhmv10',\n",
    "    start_date=\"1983-10-01\",\n",
    "    end_date=\"1985-12-31\"\n",
    "    )\n",
    "\"\"\"\n",
    "# Make a model (you are expected to see error here if you uncomment the line below)\n",
    "# mb.make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You secussessfully created a model with custom inflow type\n"
     ]
    }
   ],
   "source": [
    "# For demonstration purpose, let me assume my_data folder has the same directory of \n",
    "# nhmv10 flow type (you will use your actual directory to the folder)\n",
    "pn_config = pywrdrb.get_pn_config()\n",
    "pn_config[\"flows/my_data\"] = pn_config[\"flows/nhmv10\"]\n",
    "\n",
    "pywrdrb.load_pn_config(pn_config)\n",
    "\n",
    "# Now we can use the custom inflow type\n",
    "mb = pywrdrb.ModelBuilder(\n",
    "    inflow_type='my_data', \n",
    "    diversion_type='nhmv10',\n",
    "    start_date=\"1983-10-01\",\n",
    "    end_date=\"1985-12-31\"\n",
    "    )\n",
    "\n",
    "# Make a model (you are expected to see error here)\n",
    "mb.make_model()\n",
    "print(\"You secussessfully created a model with custom inflow type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets you need to have in your customize \"my_folder\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For flow type folder, you need to have the following files: \n",
      "\n",
      "File needed: ['catchment_inflow_mgd.csv', 'gage_flow_mgd.csv', 'predicted_inflows_mgd.csv']\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'data' not found in the attributes of 'data' folder. Please try to access 'data' through the `get()` method if 'data' exists in 'data' folder in the file system.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile needed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiles\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(pn\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mflows\u001b[38;5;241m.\u001b[39mnhmv10\u001b[38;5;241m.\u001b[39mget(file))\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m5\u001b[39m, :\u001b[38;5;241m5\u001b[39m]) \u001b[38;5;66;03m# print first 5 rows and 5 columns\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\PathNavigator\\src\\pathnavigator\\folder.py:129\u001b[0m, in \u001b[0;36mFolder.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in the attributes of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try to access \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m through the `get()` method if \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m exists in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m folder in the file system.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'data' not found in the attributes of 'data' folder. Please try to access 'data' through the `get()` method if 'data' exists in 'data' folder in the file system."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"For flow type folder, you need to have the following files: \\n\")\n",
    "pn = pywrdrb.get_pn_object()\n",
    "files = pn.flows.nhmv10.list()\n",
    "print(f\"File needed: {files}\\n\")  \n",
    "for file in files:\n",
    "    df = pd.read_csv(pn.data.flows.nhmv10.get(file))\n",
    "    print(f\"File: {file}\")\n",
    "    print(df.iloc[:5, :5]) # print first 5 rows and 5 columns\n",
    "    print(\"\\n\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For diversions type folder, you need to have the following files: \n",
      "\n",
      "File needed: ['diversion_nj_extrapolated_mgd.csv', 'diversion_nyc_extrapolated_mgd.csv', 'predicted_diversions_mgd.csv']\n",
      "\n",
      "File: diversion_nj_extrapolated_mgd.csv\n",
      "     datetime  D_R_Canal\n",
      "0  1945-01-01  85.387245\n",
      "1  1945-01-02  80.717630\n",
      "2  1945-01-03  60.037906\n",
      "3  1945-01-04  48.030325\n",
      "4  1945-01-05  56.035379\n",
      "\n",
      "\n",
      "File: diversion_nyc_extrapolated_mgd.csv\n",
      "     datetime  cannonsville  pepacton  neversink   aggregate\n",
      "0  1945-01-01           NaN       NaN        NaN  501.333527\n",
      "1  1945-01-02           NaN       NaN        NaN  501.333527\n",
      "2  1945-01-03           NaN       NaN        NaN  501.333527\n",
      "3  1945-01-04           NaN       NaN        NaN  805.273987\n",
      "4  1945-01-05           NaN       NaN        NaN  837.798981\n",
      "\n",
      "\n",
      "File: predicted_diversions_mgd.csv\n",
      "    datetime  demand_nj_lag1_regression_disagg  \\\n",
      "0  10/1/1983                         91.425844   \n",
      "1  10/2/1983                         88.815772   \n",
      "2  10/3/1983                         88.815772   \n",
      "3  10/4/1983                         86.205637   \n",
      "4  10/5/1983                         86.205637   \n",
      "\n",
      "   demand_nj_lag1_perfect_foresight  demand_nj_lag1_same_day  \\\n",
      "0                         89.140852                91.762642   \n",
      "1                         89.140852                89.140852   \n",
      "2                         86.519062                89.140852   \n",
      "3                         86.519062                86.519062   \n",
      "4                         85.863615                86.519062   \n",
      "\n",
      "   demand_nj_lag1_regression_agg  \n",
      "0                      91.425844  \n",
      "1                      88.815772  \n",
      "2                      88.815772  \n",
      "3                      86.205637  \n",
      "4                      86.205637  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"For diversions type folder, you need to have the following files: \\n\")\n",
    "pn = pywrdrb.get_pn_object()\n",
    "files = pn.data.diversions.nhmv10.list()\n",
    "print(f\"File needed: {files}\\n\")  \n",
    "for file in files:\n",
    "    df = pd.read_csv(pn.data.diversions.nhmv10.get(file))\n",
    "    print(f\"File: {file}\")\n",
    "    print(df.iloc[:5, :5]) # print first 5 rows and 5 columns\n",
    "    print(\"\\n\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More About the Global PathNavigator Object Used in PywrDRB\n",
    "\n",
    "We can get the global `PathNavigator` object used in PywrDRB by running: `pn = pywrdrb.get_pn_object()`\n",
    "\n",
    "This `pn` object contains all the directory and path information, allowing you to locate specific files used in PywrDRB within the file explorer.\n",
    "\n",
    "More `pn` operations can be found [here](https://github.com/philip928lin/PathNavigator). However, users should ONLY use pn to explore file and folder locations. It is not designed for modifications unless you fully understand what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root directory of the pywrdrb: C:\\Users\\CL\\Documents\\GitHub\\Pywr-DRB\\src\\pywrdrb\\data\n"
     ]
    }
   ],
   "source": [
    "pn = pywrdrb.get_pn_object()\n",
    "print(f\"The root directory of the pywrdrb: {pn.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "├── catchment_withdrawals\n",
      "│   └── sw_avg_wateruse_pywrdrb_catchments_mgd.csv\n",
      "├── diversions\n",
      "│   ├── diversion_nj_extrapolated_mgd.csv\n",
      "│   ├── diversion_nyc_extrapolated_mgd.csv\n",
      "│   └── predicted_diversions_mgd.csv\n",
      "├── flows\n",
      "│   ├── nhmv10\n",
      "│   ├── nhmv10_withObsScaled\n",
      "│   ├── nwmv21\n",
      "│   ├── nwmv21_withObsScaled\n",
      "│   ├── pub_nhmv10_BC_withObsScaled\n",
      "│   ├── wrf1960s_calib_nlcd2016\n",
      "│   ├── wrf2050s_calib_nlcd2016\n",
      "│   ├── wrfaorc_calib_nlcd2016\n",
      "│   ├── wrfaorc_withObsScaled\n",
      "│   ├── _hydro_model_flow_output\n",
      "│   └── _scaled_inflows\n",
      "├── observations\n",
      "│   ├── _raw\n",
      "│   ├── catchment_inflow_mgd.csv\n",
      "│   ├── gage_flow_mgd.csv\n",
      "│   └── reservoir_storage_mg.csv\n",
      "├── operational_constants\n",
      "│   ├── constants.csv\n",
      "│   ├── ffmp_reservoir_operation_daily_profiles.csv\n",
      "│   ├── ffmp_reservoir_operation_monthly_profiles.csv\n",
      "│   ├── ffmp_reservoir_operation_weekly_profiles.csv\n",
      "│   └── istarf_conus.csv\n",
      "└── spatial\n",
      "    └── to_be_determined.txt\n",
      "\n",
      "18 directories, 13 files\n"
     ]
    }
   ],
   "source": [
    "pn.scan(max_depth=2)  # scan the directory structure up to 2 levels deep\n",
    "pn.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
