{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pywr-DRB\n",
    "## Overview:\n",
    "If you want to learn how to use the [Pywr-DRB](https://github.com/Pywr-DRB/Pywr-DRB) water resource model, you are in the right place. \n",
    "\n",
    "This page is designed to introduce you to the Pywr-DRB code base, help you set up your environment, and show you how to access and begin interacting with a Pywr-DRB model instance.  \n",
    "\n",
    "### Links:\n",
    "- [The Pywr-DRB GitHub repository](https://github.com/Pywr-DRB/Pywr-DRB)\n",
    "- [The Pywr-DRB documentation site](https://pywr-drb.github.io/Pywr-DRB/intro.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial content:\n",
    "\n",
    "1. Getting Started\n",
    "2. Explanation of the Pywr-DRB code base\n",
    "    - input_data\n",
    "    - pywrdrb\n",
    "3. Interacting with a Pywr-DRB model instance\n",
    "    - Constructing and loading a pywrdrb model\n",
    "    - Nodes\n",
    "    - Parameters\n",
    "4. Running a Pywr-DRB simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1.0 Getting Started\n",
    "\n",
    "The [Pywr-DRB GitHub organization page](https://github.com/Pywr-DRB) contains three repositories at the time of writing:\n",
    "\n",
    "| Repo | Description |\n",
    "| ---- | ---- |\n",
    "| [Pywr-DRB](https://github.com/Pywr-DRB/Pywr-DRB) | This repo contains all of the code needed |\n",
    "| [DRB-Historic-Reconstruction](https://github.com/Pywr-DRB/DRB-Historic-Reconstruction) | Used to generate historic streamflow reconstructions from 1945-2022. Reconstructions are exported to the `Pywr-DRB/input_data` folder to be used for simulation. |\n",
    "| [Input-Data-Retrieval](https://github.com/Pywr-DRB/Input-Data-Retrieval) | Contains workflows for retrieving data from the USGS NWIS (for observed flows), NHMv1.0 and NWMv2.1 modeled flows. Data for Pywr-DRB relevant locations are retrieved and exported to the `Pywr-DRB/input_data` folder to be used for simulation. This process does *not* need to be repeated unless new or different datapoints are needed.  |\n",
    "\n",
    "\n",
    "\n",
    "For now, these tutorials will only require the [Pywr-DRB](https://github.com/Pywr-DRB/Pywr-DRB) repository code. Start by cloning the github repository onto your machine.  \n",
    "\n",
    "To clone the most recent version:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/Pywr-DRB/Pywr-DRB.git\n",
    "```\n",
    "\n",
    "To get Pywr-DRB version 1.01, used to replicate the results in Hamilton, Amestoy & Reed. (Under Review), clone the `diagnostic_paper` branch of the Pywr-DRB repository from GitHub:\n",
    "\n",
    "```bash\n",
    "git clone -b diagnostic_paper https://github.com/Pywr-DRB/Pywr-DRB.git\n",
    "```\n",
    "\n",
    "Create a virtual environment where you can install dependencies. \n",
    "\n",
    "For windows:\n",
    "\n",
    "```bash\n",
    "py -m pip install --upgrade pip\n",
    "py -m pip install virtualenv\n",
    "\n",
    "py -m virtualenv venv\n",
    "source venv activate # linux\n",
    "venv/Scripts/activate\n",
    "py -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Now we are ready!\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.0 Explanation of the Pywr-DRB code base\n",
    "\n",
    "Now that you have the code base available, it will be helpful to take a moment to familiarize yourself with what is inside. The sections below highlight some key folders, their contents, and how they fit into the broader Pywr-DRB model workflow. \n",
    "\n",
    "For now, these sections focus on the two most important folders in the Pywr-DRB repo:\n",
    "- Pywr-DRB/input_data\n",
    "- Pywr-DRB/pywrdrb\n",
    "### 2.1 Input Data\n",
    "\n",
    "Pywr-DRB is able to run simulations using different sets of streamflow input data. It is currently set up to run simulations using multiple different datasets, including:\n",
    "- The National Hydrologic Model version 1.0 (NHM; `\"nhmv10\"`)\n",
    "- The National Water Model version 2.1 (NWM; `\"nwmv21\"`)\n",
    "- Hybrid datasets that combine observed, scaled-observed, and model (NHM/NWM) streamflows based on model location and data availability.\n",
    "\t- Hybrid-NHM (hNHM)\n",
    "\t- Hybrid-NWM (hNWM)\n",
    "\n",
    "\n",
    "Each dataset is given a unique identifying name (e.g., `\"nhmv10\"`) which is used at multiple points in the Pywr-DRB workflow. \n",
    "\n",
    "The current input datasets which come with the Pywr-DRB repository are:\n",
    "- `\"nhmv10\"`\n",
    "- `\"nwmv21\"`\n",
    "- `\"nhmv10_withObsScaled\"`\n",
    "- `\"nwmv21_withObsScaled\"`\n",
    "\n",
    "#### 1.2.1 Necessary files for simulation:\n",
    "\n",
    "For each of the four datasets mentioned above, the necessary input files are included in the Pywr-DRB repository.  It's worth pointing out what the important input files.  Given you want to run a simulation based on a specific streamflow scenario/dataset called `<inflow_type>`, then you need to make sure you have the following files:\n",
    "\n",
    "**Streamflow data:**\n",
    "- `catchment_inflow_<inflow_type>.csv`\n",
    "\t- These are catchment inflow timeseries for each of the main Pywr-DRB nodes. Data are at a daily timescale, in millions of gallons per day (MGD).\n",
    "- `gage_flow_<inflow_type>.csv`\n",
    "\t- These are total streamflow timeseries at each of the main Pywr-DRB nodes. This data reflects pre-management streamflow conditions across the network. Units are MGD.  \n",
    "- `predicted_inflows_diversions_<inflow_type>.csv`\n",
    "\t- These are predicted N-day ahead streamflow conditions at Montague and Trenton. The value of N ranges from 2-4. These predictions are used in simulated FFMP operations at NYC reservoirs, since they seek to maintain releases downstream while being 4-days upstream. \n",
    "\n",
    "**Consumption and transbasin diversions:**\n",
    "- `sw_avg_wateruse_Pywr-DRB_Catchments.csv`\n",
    "\t- Water diversion timeseries for each of the catchments in Pywr-DRB.\n",
    "- `deliveryNJ_DRCanal_extrapolated.csv`\n",
    "\t- Daily NJ diversion data, extrapolated further back in time based on recent data. \n",
    "- `deliveryNYC_ORDM_extrapolated.csv`\n",
    "\t- Daily NYC diversion data, extrapolated further back in time based on recent data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 2.2 `pywrdrb`\n",
    "\n",
    "This folder (`pywr-DRB/pywrdrb`) is where all the code for the model lives.  \n",
    "\n",
    "There are several submodules (folders within `pywrdrb`) which are also important to be familiar with, and are described below.\n",
    "#### 2.2.1 `pywrdrb.model_data`\n",
    "\n",
    "Go to the folder `Pywr-DRB/pywrdrb/model_data/`.\n",
    "\n",
    "The file `drb_model_full_<input type>.json` contains all of the structural information defining the model. Essentially, this is a dictionary containing lists of nodes, edges, and parameters. Together, this information is used by Pywr to construct the linear program which is used to simulate operations. \n",
    "\n",
    "The model data structure as described in the [`pywr` documentation](https://pywr.github.io/pywr/json.html) is:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"metadata\": {},\n",
    "    \"timestepper\": {},\n",
    "    \"solver\": {},\n",
    "    \"nodes\": {},\n",
    "    \"edges\": {},\n",
    "    \"parameters\": {}\n",
    "}\n",
    "```\n",
    "\n",
    "In a later tutorial we will go into more detail into how these `.json` files are created. \n",
    "\n",
    "The `pywrdrb.model_data` also has some of the other `drb_model_<*>.csv` files which contain extra information that is accessed at the start of Pywr simulation. Some examples include:\n",
    "- `drb_model_istarf_conus.csv`\n",
    "\t- This file contains the STARFIT (aka ISTARF-CONUS) parameters developed by Turner et al. (2021), which are used to simulate reservoir operations at the Non-NYC reservoirs \n",
    "- `drb_model_dailyProfiles.csv` \n",
    "\t- Daily values for the different Flexible Flow Management Program (FFMP) operations classifications which are based on NYC storage level values. This is loaded by Pywr at the start of the simulation and stored in a DataFrame to be used during simulation.\n",
    "\n",
    "#### 2.2.2 `pywrdrb.parameters`\n",
    "\n",
    "Parameters are simply Python classes which are used in a Pywr simulation. They are used to track different variables during the simulation and perform specific operations. [Pywr be default has a set of built-in Parameters](https://pywr.github.io/pywr/api/pywr.parameters.html) which can be used to do basic operations. \n",
    "\n",
    "However, in many cases we need a custom parameter which will implement a custom function during simulation. These custom parameters are located in `pywrdrb.parameters`. \n",
    "\n",
    "Some characteristics of Parameters are:\n",
    "- Parameters are loaded at the start of the model simulation\n",
    "- Parameters are written as class objects \n",
    "- There can be multiple different instances of a specific Parameter in the Pywr-DRB model\n",
    "- Parameters can be linked to other parameters or nodes in the model and access data from that parameter or node during each timestep\n",
    "- Parameters store data as attributes, and access that data every timestep\n",
    "- Parameters can return a value (output) every timestep \n",
    "\n",
    "Specifically, in `pywrdrb` we have:\n",
    "- `pywrdrb.parameters.ffmp`\n",
    "\t- These parameters are used to implement the FFMP at NYC reservoirs. There is a lot packed in here, and it will be good to return to this later on.  \n",
    "- `pywrdrb.parameters.starfit`\n",
    "\t- This contains the `STARFITReservoirRelease` parameter which is used to calculate the STARFIT based reservoir releases each day for non-NYC reservoirs. The output of this parameter (if you )\n",
    "- `pywrdrb.parameters.lower_basin_ffmp`\n",
    "\t- These parameters are used to determine when and how much water from the lower basin reservoirs (Beltzville, Blue Marsh, Nockamixon) should be released to help meet the downstream flow targets. This parameter communicates with the `pywrdrb.parameters.ffmp` parameters in order to make this decision.\n",
    "- `pywrdrb.parameters.general`\n",
    "\t- Currently, this only contains a single `LaggedReservoirRelease` parameter.  \n",
    "- `pywrdrb.parameters.inflow_ensemble`\n",
    "\t- This contains parameters which are used to handle ensemble simulations in parallel. We won't run any ensembles yet, so don't worry about this for now. \n",
    "\n",
    "Later in this tutorial we will load a `pywrdrb` model and identify some parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 `pywrdrb.pre`\n",
    "\n",
    "The `pywrdrb.pre` module contains different functions used to prepare model input data. When you clone the Pywr-DRB repository, it will contain several pre-processed datasets.\n",
    "\n",
    "The `pywrdrb.pre` module contains:\n",
    "- `disaggregate_DRBC_demands.py`\n",
    "\t- Used to disaggregate demand data provided by the DRB Commission (DRBC). The demands are mapped to the Pywr-DRB catchment areas.  \n",
    "- `extrapolate_NYC_NJ_diversions.py`\n",
    "\t- Used to extend limited historic diversion data further back in time. Regressions are constructed which predict monthly diversion demands dependent on streamflow conditions. Then [[K-Nearest Neighbors|KNN]] timeseries sampling is used for temporal disaggregation from monthly to daily timeseries. \n",
    "- `predict_inflows_diversions.py`\n",
    "\t- Contains models for predicting N-day ahead inflows and diversions across the Pywr-DRB network. These predictions are used in the FFMP operations, where NYC is interested in predicting up to the 4-day ahead flow at Trenton to plan their releases accordingly. The 3- and 2-day ahead predictions are also made. \n",
    "- `prep_input_data_functions.py`\n",
    "\t- Contains several functions used in the pre-processing workflow. One example is the `subtract_upstream_catchment_inflows()` which transform total streamflow into marginal catchment inflow timeseries. These marginal inflows are used as inputs for each node in Pywr-DRB. \n",
    "\n",
    " Later, as you consider preparing new input scenarios, it will be necessary to understand these processing steps.  These preprocessing steps are explained in detail in the supplemental information for [[Hamilton, Amestoy, & Reed (2024)]]. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 `pywrdrb.post`\n",
    "\n",
    "The `pywrdrb.post` submodule contains different scripts used for post-processing simulation results. \n",
    "\n",
    "The main function used here is `pywrdrb.post.get_pywr_results()` which is designed to extract different variables of interest from the output file.  \n",
    "\n",
    "```python\n",
    "get_pywr_results(output_dir, \n",
    "\t\t\t\t model, \n",
    "\t\t\t\t results_set='all', \n",
    "\t\t\t\t scenario=0, datetime_index=None)\n",
    "```\n",
    "\n",
    "In `get_pywr_results`, the `results_set` argument specifies what type of data you want to retrieve. For example `results_set = 'major_flow'` will return the total flow at major nodes while `results_set = 'res_release'` will return reservoir release data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 `pywrdrb.plotting`\n",
    "\n",
    "This module contains different plotting functions. We won't use any of these plots yet, but keep in mind that there is a common place to store these. \n",
    "\n",
    "***\n",
    "\n",
    "### Activity: Code flowchart\n",
    "\n",
    ">**ACTIVITY:** Let's pause here and take a minute to explore the Pywr-DRB code base.  Specifically, go go through the repository and make a flowchart diagram which shows the relationships and key content for the various sub-folders in the repository. \n",
    ">\n",
    ">You might consider using a flowchart software such as [draw.io](https://app.diagrams.net/) or doing this by hand.  \n",
    ">\n",
    ">Don't get caught up in nitty-gritty details, as your understanding of the repo will change with time. \n",
    ">\n",
    ">Send Trevor a version of this flowchart once you are done. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.0 Interacting with a Pywr-DRB model instance\n",
    "\n",
    "Before running any of this code, you may need to modify the `sys.path` to make sure it can access the `pywrdrb` folder.  Assuming that this tutorial is stored in the `Pywr-DRB/notebooks/` folder, you will need to run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_to_pywrdrb = '../'\n",
    "sys.path.append(path_to_pywrdrb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Loading a Pywr model\n",
    "\n",
    "When loading a model with Pywr, we need to provide a `json` file which defines the nodes, edges, and parameters of the model (see the section 2.2.1 `pywrdrb.model_data` of this tutorial). \n",
    "\n",
    "To load the model, we use the `pywr.model.Model` class which takes the `json` filename as an input.\n",
    "\n",
    "The following code is used to specify a streamflow dataset, set the model file which we want to load, and load it using `pywr.model`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywr.model import Model \n",
    "\n",
    "# import our custom parameters, since pywr will need them to construct the model\n",
    "from pywrdrb.parameters import *\n",
    "\n",
    "# import the make_model function to generate a new JSON model file\n",
    "from pywrdrb.make_model import make_model\n",
    "\n",
    "# Options: \"nhmv10\", \"nwmv21\", \"nhmv10_withObsScaled\", \"nwmv21_withObsScaled\" \n",
    "inflow_type = 'nhmv10'   \n",
    "\n",
    "# We use the dataset name to specify the file name\n",
    "model_filename = f'drb_model_full_{inflow_type}.json'\n",
    "model_filename = f'{path_to_pywrdrb}/pywrdrb/model_data/{model_filename}'\n",
    "\n",
    "# Simulation start and end dates\n",
    "from pywrdrb.utils.dates import model_date_ranges\n",
    "start_date, end_date = model_date_ranges[inflow_type]\n",
    "\n",
    "# Make a new model JSON file\n",
    "\n",
    "make_model(inflow_type = inflow_type, \n",
    "           model_filename = model_filename, \n",
    "           start_date = start_date, \n",
    "           end_date = end_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you might not have noticed but the model file 'drb_model_full_{inflow_type}.json' was just replaced with a new version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load the pywrdrb model\n",
    "model = Model.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Nodes\n",
    "\n",
    "Nodes are the primary features in the Pywr-DRB model, and are used to represent reservoirs, USGS gauges, catchment inflow points, and other things. \n",
    "\n",
    "Take a minute to check out the [`pywr` documentation on node classes.](https://pywr.github.io/pywr/api/pywr.nodes.html)\n",
    "\n",
    "While [`pywr` does allow for custom nodes](https://pywr.github.io/pywr/extending_pywr/index.html), we are not currently using any of these in `pywrdrb`.\n",
    "\n",
    "The code below allows you to make a list of the model nodes. Run the code and count the number of nodes in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 177 nodes in the model.\n"
     ]
    }
   ],
   "source": [
    "# Make a list of all model nodes\n",
    "model_nodes = [n for n in model.nodes if n.name]\n",
    "\n",
    "print(f'There are {len(model_nodes)} nodes in the model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Parameters\n",
    "\n",
    "We can do the same thing for the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 394 parameters in the model\n"
     ]
    }
   ],
   "source": [
    "### Read model parameter names into a list\n",
    "model_parameters = [p for p in model.parameters if p.name]\n",
    "model_parameter_names = [p.name for p in model_parameters]\n",
    "\n",
    "print(f'There are {len(model_parameters)} parameters in the model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.0 Running a Pywr-DRB simulation\n",
    "\n",
    "Once we have loaded the `model`, we are almost ready to run a simulation. \n",
    "\n",
    "First, we need to initializes a `pywr.recorders.TablesRecorder` which will keep store simulation data during the model run. The `TablesRecorder` will automatically create a `hdf5` file where it will store simulation data.\n",
    "\n",
    "The recorder accepts as input:\n",
    "- The `model` object\n",
    "- The `output_filename`\n",
    "- A list of model parameters\n",
    "\n",
    "The code below is used to initialize the `TablesRecorder`, run the simulation!\n",
    "\n",
    "This should take 3-5 minutes to complete the full simulation.\n",
    "\n",
    "(You will likely see many warnings pop up; don't worry about those unless the simulation actually stops..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pywr.recorders.TablesRecorder class is used store simulation results\n",
    "# the simulation data is stored in an hdf5 file which is accessed during the simulation\n",
    "from pywr.recorders import TablesRecorder\n",
    "\n",
    "# there are a few naming convention warnings pywr, we can ignore them\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "output_filename = f'drb_output_{inflow_type}.hdf5'\n",
    "output_filename = f'../output_data/{output_filename}'\n",
    "\n",
    "### Add a storage recorder\n",
    "TablesRecorder(model = model, \n",
    "\t\t\t   h5file = output_filename, \n",
    "\t\t\t   parameters = model_parameters)\n",
    "\n",
    "### Run the model\n",
    "stats = model.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you've just completed your first simulation using `pywrdrb`!\n",
    "\n",
    "\n",
    "***\n",
    "## 5.0 Accessing Pywr-DRB output data\n",
    "\n",
    "The data will be output to a HDF5 file in the Pywr-DRB/output_data/ folder. \n",
    "\n",
    "These HDF5 files can be a little tricky if you don't have experience with them.  We have made a function which makes it easy to load specific types of variables from these output files. \n",
    "\n",
    "The function is called `pywrdrb.post.get_pywrdrb_results()` and requires a `results_set` input which specifies the type of variables that you would like to get back. \n",
    "\n",
    "Some of the `results_set` options are:\n",
    "- \"all\"\n",
    "- \"res_storage\"\n",
    "- \"major_flow\"\n",
    "- \"res_release\"\n",
    "- \"inflow\"\n",
    "\n",
    "\n",
    "Go look inside the `pywrdrb.post.get_pywrdrb_results()` function to see the other `results_set` options. \n",
    "\n",
    "One thing to note is that the `get_pywrdrb_results()` function returns a tuple containing `(results_set, datetime)` where `datetime` is a pandas index containing daily indexes that match the results.  The reason it returns the datetime index is that the `get_pywrdrb_results()` function is very slow when reading and constructing the date data from the output file. Rather than read/construct the datetime each time, we can do this only once and then re-use the datetime index for each of the subsequant function calls. We can re-use the `datetime` since `get_pywr_results()` accepts `datetime_index` as an input. By default, `datetime_index=None` and the function will read/construct the datetime from the output. To be more efficient, we pass the returned `datetime` to the next function after it is created. See how this is done in the example below. \n",
    "\n",
    "\n",
    "### 5.1 The structure of `results_set` dictionary\n",
    "\n",
    "The `get_pywrdrb_results()` function gathers simulation results from Pywr model run and returns a dictionary of pd.DataFrames where each key in the dict corresponds to a scenario.\n",
    "\n",
    "This will look like:\n",
    "\n",
    "```python\n",
    "results_set  = {\n",
    "    0 : \n",
    "    pd.DataFrame(<simulation results>)\n",
    "}\n",
    "```\n",
    "\n",
    "For non-ensemble simulations, there is only a single scenario. Consequently, this dictionary will have a single key:value pair. \n",
    "\n",
    "The pd.DataFrame will contain the simulation data with a datetime index. \n",
    "\n",
    "Let's load the `results_set=\"major_flows\"` from the simulation run above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01417000</th>\n",
       "      <th>01425000</th>\n",
       "      <th>01433500</th>\n",
       "      <th>01436000</th>\n",
       "      <th>01447800</th>\n",
       "      <th>01449800</th>\n",
       "      <th>01463620</th>\n",
       "      <th>01470960</th>\n",
       "      <th>delDRCanal</th>\n",
       "      <th>delLordville</th>\n",
       "      <th>delMontague</th>\n",
       "      <th>delTrenton</th>\n",
       "      <th>outletAssunpink</th>\n",
       "      <th>outletSchuylkill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983-10-01</th>\n",
       "      <td>245.248604</td>\n",
       "      <td>192.037241</td>\n",
       "      <td>702.126510</td>\n",
       "      <td>216.100859</td>\n",
       "      <td>1296.612713</td>\n",
       "      <td>30.526917</td>\n",
       "      <td>77.324137</td>\n",
       "      <td>981.138761</td>\n",
       "      <td>872.861166</td>\n",
       "      <td>626.737443</td>\n",
       "      <td>1050.155248</td>\n",
       "      <td>804.943656</td>\n",
       "      <td>110.874962</td>\n",
       "      <td>329.747828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-10-02</th>\n",
       "      <td>157.896171</td>\n",
       "      <td>150.911779</td>\n",
       "      <td>716.300505</td>\n",
       "      <td>60.483957</td>\n",
       "      <td>1298.492457</td>\n",
       "      <td>32.752592</td>\n",
       "      <td>77.732775</td>\n",
       "      <td>982.026219</td>\n",
       "      <td>1837.957440</td>\n",
       "      <td>514.753462</td>\n",
       "      <td>2386.712148</td>\n",
       "      <td>1772.532316</td>\n",
       "      <td>132.337899</td>\n",
       "      <td>688.332292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-10-03</th>\n",
       "      <td>227.762061</td>\n",
       "      <td>193.806146</td>\n",
       "      <td>706.181702</td>\n",
       "      <td>203.568972</td>\n",
       "      <td>1294.352344</td>\n",
       "      <td>30.018671</td>\n",
       "      <td>77.890367</td>\n",
       "      <td>978.970950</td>\n",
       "      <td>4459.188059</td>\n",
       "      <td>640.682999</td>\n",
       "      <td>2799.830204</td>\n",
       "      <td>4394.386031</td>\n",
       "      <td>114.075338</td>\n",
       "      <td>1740.349575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              01417000    01425000    01433500    01436000     01447800  \\\n",
       "1983-10-01  245.248604  192.037241  702.126510  216.100859  1296.612713   \n",
       "1983-10-02  157.896171  150.911779  716.300505   60.483957  1298.492457   \n",
       "1983-10-03  227.762061  193.806146  706.181702  203.568972  1294.352344   \n",
       "\n",
       "             01449800   01463620    01470960   delDRCanal  delLordville  \\\n",
       "1983-10-01  30.526917  77.324137  981.138761   872.861166    626.737443   \n",
       "1983-10-02  32.752592  77.732775  982.026219  1837.957440    514.753462   \n",
       "1983-10-03  30.018671  77.890367  978.970950  4459.188059    640.682999   \n",
       "\n",
       "            delMontague   delTrenton  outletAssunpink  outletSchuylkill  \n",
       "1983-10-01  1050.155248   804.943656       110.874962        329.747828  \n",
       "1983-10-02  2386.712148  1772.532316       132.337899        688.332292  \n",
       "1983-10-03  2799.830204  4394.386031       114.075338       1740.349575  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pywrdrb.post import get_pywrdrb_results\n",
    "\n",
    "# Get major flow results\n",
    "major_flows, datetime = get_pywrdrb_results(output_dir= '../output_data/',\n",
    "                           model = inflow_type, \n",
    "                           scenarios=[0], \n",
    "                           results_set= 'major_flow')\n",
    "\n",
    "# Get reservoir release results\n",
    "# Now we can re-use the datetime index from above, to speed up retrieval\n",
    "res_releases, datetime = get_pywrdrb_results(output_dir= '../output_data/',\n",
    "                           model = inflow_type, \n",
    "                           scenarios=[0], \n",
    "                           results_set= 'res_release',\n",
    "                           datetime_index=datetime)\n",
    "\n",
    "major_flows[0].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a DataFrame with multiple columns corresponding to each of the reservoirs in the model. \n",
    "\n",
    "Now you can get into the fun of looking at results and some data visualization!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Summary of Training and Activities\n",
    "\n",
    "You've just made it to the end of the first Pywr-DRB training. Wooo!\n",
    "\n",
    "Just to recap, in this training we considered:\n",
    "1. [Getting Started](#10-getting-started) by cloning the repository and creating your virtual environment\n",
    "2. [Explanation of the Pywr-DRB code base](#20-explanation-of-the-pywr-drb-code-base) with a focus on key folders and files.  \n",
    "    - [input_data](#21-input-data)\n",
    "    - [pywrdrb](#22-pywrdrb)\n",
    "3. [Interacting with a Pywr-DRB model instance](#30-interacting-with-a-pywr-drb-model-instance)\n",
    "    - [Constructing and loading a pywrdrb model](#31-loading-a-pywr-model)\n",
    "    - [Nodes](#32-nodes)\n",
    "    - [Parameters](#33-parameters)\n",
    "4. [Running a Pywr-DRB simulation](#40-running-a-pywr-drb-simulation)\n",
    "\n",
    "\n",
    "To make the most of this training, I recommend that you complete the activities from this training, including:\n",
    "- [Make a flow chart of the key elements of the Pywr-DRB code base](#activity-code-flowchart)\n",
    "- Run an instance of the Pywr-DRB model\n",
    "- Load and visualize some of the output data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
